{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"C3D_with_colab.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1HofU29uPnYklMA0GkVGfOEXqMiM4rtSn","authorship_tag":"ABX9TyN65h90wnQZQyIn80CyNqRs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GkwKki9ctzVp","colab_type":"text"},"source":["# caffe2를 GPU 버전으로 설치\n","https://stackoverflow.com/questions/48500120/may-i-install-caffe-or-caffe2-on-google-colaboratory"]},{"cell_type":"code","metadata":{"id":"TPGlONa4AYH5","colab_type":"code","colab":{}},"source":["!apt install -y caffe-cuda"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xmRWfb6NuaCK","colab_type":"text"},"source":["# 깃허브 보고 따라하기 1\n","https://github.com/rutviz/anomaly-detection\n","- training안의 ipynb 따라함"]},{"cell_type":"code","metadata":{"id":"weMqUtm1Anub","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600089687744,"user_tz":-540,"elapsed":938,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}},"outputId":"4fadebc9-6bc2-4b80-ab03-e1952afb381b"},"source":["##### required\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wt5AURi9uoKv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":198},"executionInfo":{"status":"ok","timestamp":1600089724741,"user_tz":-540,"elapsed":4975,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}},"outputId":"881fae67-d9df-449d-c53e-d464107c59e2"},"source":["#### required\n","!pip install configparser"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting configparser\n","  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n","Installing collected packages: configparser\n","Successfully installed configparser-5.0.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["configparser"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ddWesojhuoHY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":410},"executionInfo":{"status":"ok","timestamp":1600089737852,"user_tz":-540,"elapsed":5659,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}},"outputId":"9c474416-b378-4cc1-c118-b205db8a8a94"},"source":["##### required\n","!pip install keras==1.1.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting keras==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/5e/7e64f15f0e5ae65a29c738fc261ce1e0a72d92acfc45f06ef906c6e84bf2/Keras-1.1.0.tar.gz (150kB)\n","\u001b[K     |████████████████████████████████| 153kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==1.1.0) (1.0.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==1.1.0) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==1.1.0) (1.15.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==1.1.0) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==1.1.0) (1.18.5)\n","Building wheels for collected packages: keras\n","  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras: filename=Keras-1.1.0-cp36-none-any.whl size=178685 sha256=ede9d5d45df0bc35256e52afd78d3791df913c78196d78341380e735b692e2dc\n","  Stored in directory: /root/.cache/pip/wheels/ae/83/3e/c42ce0672e537640ee706143ebdd1dd691b7693b4ca50f72a8\n","Successfully built keras\n","\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: kapre 0.1.3.1 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fancyimpute 0.4.3 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed keras-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yg3IEL23uoFr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1600161087202,"user_tz":-540,"elapsed":4059,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}},"outputId":"ddee3d9d-6489-4b06-ac8d-e20536ee54c2"},"source":["##### required\n","# 이유는 모르겠는데 런타임할 때마다 install해야함\n","!pip install path.py"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting path.py\n","  Downloading https://files.pythonhosted.org/packages/8f/04/130b7a538c25693c85c4dee7e25d126ebf5511b1eb7320e64906687b159e/path.py-12.5.0-py3-none-any.whl\n","Collecting path\n","  Downloading https://files.pythonhosted.org/packages/cb/81/b9090d24e60369fd9413b92fcd87e13a37bf43dad3427d35e09915f788ac/path-15.0.0-py3-none-any.whl\n","Installing collected packages: path, path.py\n","Successfully installed path-15.0.0 path.py-12.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0JcXQ80duv_h","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600161479783,"user_tz":-540,"elapsed":4462,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}}},"source":["# from keras.models import Sequential 에서 모든 keras앞에 tensorflow.을 붙임\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM, Reshape\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import SGD, Adam, Adagrad\n","from scipy.io import loadmat, savemat\n","from tensorflow.keras.models import model_from_json\n","import theano.tensor as T\n","import tensorflow as tf\n","import theano\n","import configparser\n","import collections\n","import time\n","import path\n","import os\n","from os import listdir\n","import skimage.transform\n","from skimage import color\n","import numpy as np\n","import numpy\n","from datetime import datetime"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"0cWchmIRuv3Y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600161481843,"user_tz":-540,"elapsed":732,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}}},"source":["def save_model(model, json_path, weight_path):\n","    json_string = model.to_json()\n","    open(json_path, 'w').write(json_string)\n","    dict = {}\n","    i = 0\n","    for layer in model.layers:\n","        weights = layer.get_weights()\n","        my_list = np.zeros(len(weights), dtype=np.object)\n","        my_list[:] = weights\n","        dict[str(i)] = my_list\n","        i += 1\n","    savemat(weight_path, dict)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5YJXB5AyLPR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600161483222,"user_tz":-540,"elapsed":762,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}}},"source":["def load_model(json_path):  # Function to load the model\n","    model = model_from_json(open(json_path).read())    # encoding=\"UTF-8\"을 넣으려고 했지만 실패\n","    return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqbBMXXuyLT2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600161486321,"user_tz":-540,"elapsed":739,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}}},"source":["def load_dataset_Train_batch(AbnormalPath, NormalPath):\n","  \n","    batchsize=60\n","    n_exp= int(batchsize/2)\n","\n","    Num_abnormal = 900\n","    Num_Normal = 792.\n","\n","\n","    Abnor_list_iter = np.random.permutation(Num_abnormal)\n","    Abnor_list_iter = Abnor_list_iter[Num_abnormal-n_exp:]\n","    Norm_list_iter = np.random.permutation(Num_Normal)\n","    Norm_list_iter = Norm_list_iter[Num_Normal-n_exp:]\n","    \n","    All_Videos=[]\n","    with open(AbnormalPath+\"/anomaly.txt\", 'r') as f1: #file contain path to anomaly video file.\n","      for line in f1:\n","          All_Videos.append(line.strip())\n","    AllFeatures = []\n","    print(\"Loading Anomaly videos Features...\")\n","\n","    Video_count=-1\n","    for iv in Abnor_list_iter:\n","        Video_count=Video_count+1\n","        VideoPath = os.path.join(AbnormalPath, All_Videos[iv])\n","        f = open(VideoPath, \"r\")\n","        words = f.read().split()\n","        num_feat = len(words) / 4096\n","        \n","        count = -1;\n","        VideoFeatues = []\n","        for feat in range(0, int(num_feat)):\n","            feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n","            count = count + 1\n","            if count == 0:\n","                VideoFeatues = feat_row1\n","            if count > 0:\n","                VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n","\n","        if Video_count == 0:\n","            AllFeatures = VideoFeatues\n","        if Video_count > 0:\n","            AllFeatures = np.vstack((AllFeatures, VideoFeatues))\n","    print(\" Abnormal Features  loaded\")\n","\n","    All_Videos=[]\n","    with open(NormalPath+\"/normal.txt\", 'r') as f1: #file contain path to normal video file.\n","        for line in f1:\n","            All_Videos.append(line.strip())\n","    \n","    print(\"Loading Normal videos...\")\n","  \n","    for iv in Norm_list_iter:\n","        VideoPath = os.path.join(NormalPath, All_Videos[iv])\n","        f = open(VideoPath, \"r\")\n","        words = f.read().split()\n","        feat_row1 = np.array([])\n","        num_feat = len(words) /4096\n","        count = -1;\n","        VideoFeatues = []\n","        for feat in range(0, int(num_feat)):\n","            feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n","            count = count + 1\n","            if count == 0:\n","                VideoFeatues = feat_row1\n","            if count > 0:\n","                VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n","            feat_row1 = []\n","        AllFeatures = np.vstack((AllFeatures, VideoFeatues))\n","\n","    print(\"Features  loaded\")\n","\n","    AllLabels = np.zeros(32*batchsize, dtype='uint8')\n","    th_loop1=n_exp*32\n","    th_loop2=n_exp*32-1\n","\n","    for iv in range(0, 32*batchsize):\n","            if iv< th_loop1:\n","                AllLabels[iv] = int(0)\n","            if iv > th_loop2:\n","                AllLabels[iv] = int(1)\n","\n","    return  AllFeatures,AllLabels"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvBSLOADyLG_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600161490921,"user_tz":-540,"elapsed":749,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}}},"source":["#For custom loss function - ref = https://towardsdatascience.com/advanced-keras-constructing-complex-custom-losses-and-metrics-c07ca130a618. \n","\n","def custom_objective(y_true, y_pred):\n","\n","    y_true = T.flatten(y_true)\n","    y_pred = T.flatten(y_pred)\n","   \n","    n_seg = 32\n","    nvid = 60\n","    n_exp = nvid / 2\n","    Num_d=32*nvid\n","\n","    sub_max = T.ones_like(y_pred)\n","    sub_sum_labels = T.ones_like(y_true)\n","    sub_sum_l1=T.ones_like(y_true) \n","    sub_l2 = T.ones_like(y_true)\n","\n","    for ii in range(0, nvid, 1):\n","      \n","        mm = y_true[ii * n_seg:ii * n_seg + n_seg]\n","        sub_sum_labels = T.concatenate([sub_sum_labels, T.stack(T.sum(mm))])\n","\n","        Feat_Score = y_pred[ii * n_seg:ii * n_seg + n_seg]\n","        sub_max = T.concatenate([sub_max, T.stack(T.max(Feat_Score))])  \n","        sub_sum_l1 = T.concatenate([sub_sum_l1, T.stack(T.sum(Feat_Score))])\n","\n","        z1 = T.ones_like(Feat_Score)\n","        z2 = T.concatenate([z1, Feat_Score])\n","        z3 = T.concatenate([Feat_Score, z1])\n","        z_22 = z2[31:]\n","        z_44 = z3[:33]\n","        z = z_22 - z_44\n","        z = z[1:32]\n","        z = T.sum(T.sqr(z))\n","        sub_l2 = T.concatenate([sub_l2, T.stack(z)])\n","\n","\n","    sub_score = sub_max[Num_d:]\n","    F_labels = sub_sum_labels[Num_d:]\n","    \n","\n","    sub_sum_l1 = sub_sum_l1[Num_d:]\n","    sub_sum_l1 = sub_sum_l1[:n_exp]\n","    sub_l2 = sub_l2[Num_d:]\n","    sub_l2 = sub_l2[:n_exp]\n","\n","    indx_nor = theano.tensor.eq(F_labels, 32).nonzero()[0]\n","    indx_abn = theano.tensor.eq(F_labels, 0).nonzero()[0]\n","\n","    n_Nor=n_exp\n","\n","    Sub_Nor = sub_score[indx_nor]\n","    Sub_Abn = sub_score[indx_abn]\n","\n","    z = T.ones_like(y_true)\n","    for ii in range(0, n_Nor, 1):\n","        sub_z = T.maximum(1 - Sub_Abn + Sub_Nor[ii], 0)\n","        z = T.concatenate([z, T.stack(T.sum(sub_z))])\n","\n","    z = z[Num_d:]\n","    z = T.mean(z, axis=-1) +  0.00008*T.sum(sub_sum_l1) + 0.00008*T.sum(sub_l2)\n","\n","    return z"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2K99WQ2ymoI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":401},"executionInfo":{"status":"error","timestamp":1600161565892,"user_tz":-540,"elapsed":6771,"user":{"displayName":"최서윤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwZGkUZqiYw3xHdV1cCS1S_q0Rlh15mLgIMRwm=s64","userId":"00430026924922124027"}},"outputId":"d98e99fb-c7fa-43ce-b6dd-1c7f0c17dd70"},"source":["# Path contains C3D features (.txt file) of each video.\n","# Each text file contains 32 features, each of 4096 dimension\n","\n","\n","# AllClassPath='/content/drive/My Drive/C3D/C3D-v1.0/examples/c3d_feature_extraction/out' 를 아래로 변경\n","AllClassPath='/content/drive/My Drive/Colab Notebooks/C3D'    # 각 비디오의 C3D features(txt file)을 가지고 있는 경로\n","\n","# output_dir='/content/' 를 아래로 변경\n","output_dir='/content/drive/My Drive/Colab Notebooks/C3D'    # 결과를 저장할 경로\n","\n","# Output_dir save trained weights and model.\n","weights_path = output_dir + 'weights.mat'    # 훈련된 모델의 가중치\n","model_path = output_dir + 'model.json'    # 훈련된 가중치를 보관하는 폴더\n","\n","# model=load_model(\"/content/drive/My Drive/C3D/C3D-v1.0/examples/c3d_feature_extraction/out/\"+model_path) 를 아래로 변경\n","# model=load_model(\"/content/drive/My Drive/Colab Notebooks/C3D\"+model_path) 했는데 오류나서 visual코드보니까 없길래 다시 주석처리함\n","\n","\n","# .py에는 이렇게 되어있음\n","# model=load_model(model_path)\n","# load_weights(model, weights_path)\n","# nVideos=len(All_Test_files)\n","# time_before = datetime.now()\n","\n","\n","# Create Full connected Model\n","model = Sequential()\n","model.add(Dense(512, input_dim=4096,kernel_initializer='glorot_normal',kernel_regularizer=l2(0.001),activation='relu'))\n","model.add(Dropout(0.6))\n","model.add(Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=l2(0.001)))\n","model.add(Dropout(0.6))\n","model.add(Dense(1,kernel_initializer='glorot_normal',kernel_regularizer=l2(0.001),activation='sigmoid'))\n","\n","adagrad=Adagrad(lr=0.01, epsilon=1e-08)\n","\n","model.compile(loss=custom_objective, optimizer=adagrad)\n","\n","if not os.path.exists(output_dir):\n","       os.makedirs(output_dir)\n","\n","All_class_files= listdir(AllClassPath)\n","All_class_files.sort()\n","loss_graph =[]\n","num_iters = 20000\n","total_iterations = 0\n","batchsize=60\n","time_before = datetime.now()\n","\n","for it_num in range(num_iters):\n","    inputs, targets=load_dataset_Train_batch(AllClassPath, AllClassPath)\n","    batch_loss =model.train_on_batch(inputs, targets)\n","    loss_graph = np.hstack((loss_graph, batch_loss))\n","    total_iterations += 1\n","    if total_iterations % 20 == 1:\n","        print (\"These iteration=\" + str(total_iterations) + \") took: \" + str(datetime.now() - time_before) + \", with loss of \" + str(batch_loss))\n","\n","save_model(model, model_path, weights_path)"],"execution_count":7,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-cdfc48de3955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_dataset_Train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllClassPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAllClassPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mloss_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-80501dac511b>\u001b[0m in \u001b[0;36mload_dataset_Train_batch\u001b[0;34m(AbnormalPath, NormalPath)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mAbnor_list_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNum_abnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mAbnor_list_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbnor_list_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNum_abnormal\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_exp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mNorm_list_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNum_Normal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mNorm_list_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNorm_list_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNum_Normal\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_exp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.permutation\u001b[0;34m()\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: x must be an integer or at least 1-dimensional"]}]},{"cell_type":"code","metadata":{"id":"8LXpk6M3BBwq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}