{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions\n",
    "\n",
    "def check_num_epochs(run):\n",
    "    num_epochs = 40\n",
    "    if Path(run / \"valid_log.csv\").is_file():\n",
    "        valid_log = pd.read_csv(run / \"valid_log.csv\", index_col=0)\n",
    "        if len(valid_log) != num_epochs:\n",
    "            print(\"Wrong number of epochs in run: {}\".format(run))\n",
    "    else:\n",
    "        print(\"valid_log.csv not exists in run: {}\".format(run))\n",
    "\n",
    "def collect_one(model_name, run, csv_file):\n",
    "    check_num_epochs(run)\n",
    "    \n",
    "    cfg = OmegaConf.load(run / '.hydra' / 'config.yaml')\n",
    "    \n",
    "    mode = cfg['data']['validation']['mode']\n",
    "    seed = cfg['data']['validation'].get('split_seed', cfg.get('seed', -1))\n",
    "    \n",
    "    csv_path = run / 'test_predictions' / csv_file\n",
    "    if not csv_path.exists():\n",
    "        print(f'Skipping not found: {csv_path}')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    data = pd.read_csv(csv_path, index_col=0)\n",
    "    if data.empty:\n",
    "        print(f'Pred file is empty: {csv_path}')\n",
    "    \n",
    "    data['model'] = model_name\n",
    "    data['split_seed'] = seed\n",
    "    data['mode'] = mode\n",
    "    \n",
    "    return data\n",
    "\n",
    "def collect_all(model_name, root, csv_file):\n",
    "    root = Path(root)\n",
    "    \n",
    "    metrics = [collect_one(model_name, run, csv_file) for run in list(root.glob(\"run-*\"))]\n",
    "        \n",
    "    metrics = pd.concat(metrics, ignore_index=True)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for each detected run\n",
    "\n",
    "def compute_metrics(data, grouping):\n",
    "    columns = ['Model', 'Mode', 'Split Seed', 'Accuracy', 'Precision', 'Recall', 'F1', 'False Alarm', 'Missing Alarm', 'ROC AUC']\n",
    "    metrics = []\n",
    "    \n",
    "    data = data.copy().reset_index()\n",
    "    grouped = data.groupby(grouping)\n",
    "    \n",
    "    for model_group, predictions in grouped:\n",
    "        model_name, mode, split_seed = model_group[0], model_group[1], model_group[2]\n",
    "        \n",
    "        targets = predictions['target_label'].values\n",
    "        preds = predictions['pred_label'].values\n",
    "        probs = predictions['pred_prob'].values\n",
    "        \n",
    "        conf_matrix = confusion_matrix(targets, preds)\n",
    "        TN = conf_matrix[0][0]\n",
    "        FN = conf_matrix[1][0]\n",
    "        TP = conf_matrix[1][1]\n",
    "        FP = conf_matrix[0][1]\n",
    "        \n",
    "        accuracy = (TP+TN) / (TP+TN+FP+FN)\n",
    "        precision = TP / (TP+FP)\n",
    "        recall = TP / (TP+FN)\n",
    "        f1_score = 2 * ((precision*recall) / (precision+recall))\n",
    "        false_alarm = FP / (TN+FP)\n",
    "        missing_alarm = FN / (TP+FN)\n",
    "        roc_auc_value = roc_auc_score(targets, probs)\n",
    "        \n",
    "        metrics.append([model_name, mode, split_seed, accuracy, precision, recall, f1_score, false_alarm, missing_alarm, roc_auc_value])\n",
    "        \n",
    "    metrics_df = pd.DataFrame(metrics, columns=columns)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def summarize_metrics(metrics, grouping, metric_name='Accuracy'):\n",
    "    mean_metrics = metrics.groupby(['Model', 'Mode'])[['Accuracy', 'Precision', 'Recall', 'F1', 'False Alarm', 'Missing Alarm', 'ROC AUC']].aggregate(['mean', 'std'])\n",
    "    \n",
    "    return mean_metrics\n",
    "\n",
    "\n",
    "default_fields_dict = {\n",
    "    'Mode': lambda x: 'frame-diff' if x == 'frame-difference' else 'color'\n",
    "}\n",
    "\n",
    "def render_to_latex(metrics, rename_func=default_fields_dict, **latex_kwargs):\n",
    "    m = metrics.copy()\n",
    "    # renaming\n",
    "    for col, lambda_fn in rename_func.items():\n",
    "        m[col] = m[col].apply(lambda_fn)\n",
    "    m = m.groupby(['Model', 'Mode'])[['Accuracy', 'F1', 'False Alarm', 'Missing Alarm', 'ROC AUC']].aggregate(lambda x: u\"{:.2f}\\u00B1{:.2f}\".format(x.mean(), x.std()))\n",
    "    ltex = m.style.to_latex(\n",
    "        **latex_kwargs\n",
    "    )\n",
    "    return ltex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve n names of videos not correctly predicted for each run\n",
    "\n",
    "def retrieve_wrong_predictions(data, grouping, n=3):\n",
    "    columns = ['Model', 'Video Names']\n",
    "    video_names = []\n",
    "    \n",
    "    data = data.copy().reset_index()\n",
    "    grouped = data.groupby(grouping)\n",
    "    \n",
    "    for model_name, predictions in grouped:\n",
    "        model_name = model_name[0] + \"_\" + model_name[1] + \"_\" + \"run-{}\".format(model_name[2])\n",
    "        \n",
    "        ids = predictions['video_id'].values\n",
    "        targets = predictions['target_label'].values\n",
    "        preds = predictions['pred_label'].values\n",
    "        probs = predictions['pred_prob'].values\n",
    "        \n",
    "        wrong_video_indexes = [i for i, (t, p) in enumerate(zip(targets, preds)) if t != p]\n",
    "        \n",
    "        n = n if n < len(wrong_video_indexes) else len(wrong_video_indexes)\n",
    "        model_video_names = \"\"\n",
    "        for i in range(n):\n",
    "            model_video_names += \"{}, \".format(ids[wrong_video_indexes[i]])\n",
    "            \n",
    "        video_names.append([model_name, model_video_names]) \n",
    "        \n",
    "    wrong_videos_df = pd.DataFrame(video_names, columns=columns)\n",
    "        \n",
    "    return wrong_videos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cross-Dataset Evaluation</h1>\n",
    "<p>Train exploiting some datasets, test against the whole Bus Violence Dataset</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-training on Surveillance Camera Fight</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROOT = \"/home/luca/dlearning/results/video-violence-detection/\"\n",
    "\n",
    "runs = {\n",
    "    'BiConvLSTM-ECCV2018': list(Path(ROOT + '/runs/experiment=surveillance-camera-fight/').glob('biconvlstm-eccv*')),\n",
    "    'ConvLSTM-AVSS2017': list(Path(ROOT + '/runs/experiment=surveillance-camera-fight').glob('convlstm-avss*')),\n",
    "    'ResNet18-2+1D': list(Path(ROOT + '/runs/experiment=surveillance-camera-fight/').glob('resnet18-2plus1d*')),\n",
    "    'ResNet18-3D': list(Path(ROOT + '/runs/experiment=surveillance-camera-fight/').glob('resnet18-3d*')),\n",
    "    'SlowFast': list(Path(ROOT + '/runs/experiment=surveillance-camera-fight/').glob('slowfast*')),\n",
    "    'Video-Swim-Transformer-k400': list(Path(ROOT + '/runs/experiment=surveillance-camera-fight/').glob('videoswintransformer-k400*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions scanning runs\n",
    "predictions = pd.concat([collect_all(k, r, 'preds_bus-violence.csv') for k, v in runs.items() for r in v], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing metrics\n",
    "model_grouper = ['model', 'mode', 'split_seed']\n",
    "metrics = compute_metrics(predictions, model_grouper)\n",
    "\n",
    "display(metrics)\n",
    "\n",
    "summary = summarize_metrics(metrics, model_grouper)\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain LaTeX table for the paper\n",
    "\n",
    "latex = render_to_latex(\n",
    "    metrics, \n",
    "    caption=\"Cross-Dataset evaluation (pre-training on Surveillance Camera Fight, test on Bus Dataset)\",\n",
    "    clines=\"skip-last;data\",\n",
    "    hrules=True,\n",
    "    column_format=\"llccccc\"\n",
    ")\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-training on Real Life Violence Situations Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/home/luca/dlearning/results/video-violence-detection/\"\n",
    "\n",
    "runs = {\n",
    "    'BiConvLSTM-ECCV2018': list(Path(ROOT + '/runs/experiment=real-life-violence/').glob('biconvlstm-*')),\n",
    "    'ConvLSTM-AVSS2017': list(Path(ROOT + '/runs/experiment=real-life-violence/').glob('convlstm-*')),\n",
    "    'ResNet18-2+1D': list(Path(ROOT + '/runs/experiment=real-life-violence/').glob('resnet18-2plus1d*')),\n",
    "    'ResNet18-3D': list(Path(ROOT + '/runs/experiment=real-life-violence/').glob('resnet18-3d*')),\n",
    "    'SlowFast': list(Path(ROOT + '/runs/experiment=real-life-violence/').glob('slowfast*')),\n",
    "    'Video-Swim-Transformer-k400': list(Path(ROOT + '/runs/experiment=real-life-violence/').glob('videoswintransformer-k400*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions scanning runs\n",
    "predictions = pd.concat([collect_all(k, r, 'preds_bus-violence.csv') for k, v in runs.items() for r in v], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing metrics\n",
    "model_grouper = ['model', 'mode', 'split_seed']\n",
    "metrics = compute_metrics(predictions, model_grouper)\n",
    "\n",
    "display(metrics)\n",
    "\n",
    "summary = summarize_metrics(metrics, model_grouper)\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain LaTeX table for the paper\n",
    "\n",
    "latex = render_to_latex(\n",
    "    metrics, \n",
    "    caption=\"Cross-Dataset evaluation (pre-training on Real Life Violence Situations Dataset, test on Bus Dataset)\",\n",
    "    clines=\"skip-last;data\",\n",
    "    hrules=True,\n",
    "    column_format=\"llccccc\"\n",
    ")\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-training on RWF-2000 Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/home/luca/dlearning/results/video-violence-detection/\"\n",
    "\n",
    "runs = {\n",
    "    'BiConvLSTM-ECCV2018': list(Path(ROOT + '/runs/experiment=RWF-2000/').glob('biconvlstm-*')),\n",
    "    'ConvLSTM-AVSS2017': list(Path(ROOT + '/runs/experiment=RWF-2000/').glob('convlstm-*')),\n",
    "    'ResNet18-2+1D': list(Path(ROOT + '/runs/experiment=RWF-2000/').glob('resnet18-2plus1d*')),\n",
    "    'ResNet18-3D': list(Path(ROOT + '/runs/experiment=RWF-2000/').glob('resnet18-3d*')),\n",
    "    'SlowFast': list(Path(ROOT + '/runs/experiment=RWF-2000/').glob('slowfast*')),\n",
    "    'Video-Swim-Transformer-k400': list(Path(ROOT + '/runs/experiment=RWF-2000/').glob('videoswintransformer-k400*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions scanning runs\n",
    "predictions = pd.concat([collect_all(k, r, 'preds_bus-violence.csv') for k, v in runs.items() for r in v], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing metrics\n",
    "model_grouper = ['model', 'mode', 'split_seed']\n",
    "metrics = compute_metrics(predictions, model_grouper)\n",
    "\n",
    "display(metrics)\n",
    "\n",
    "summary = summarize_metrics(metrics, model_grouper)\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain LaTeX table for the paper\n",
    "\n",
    "latex = render_to_latex(\n",
    "    metrics, \n",
    "    caption=\"Cross-Dataset evaluation (pre-training on RWF-2000 Dataset, test on Bus Dataset)\",\n",
    "    clines=\"skip-last;data\",\n",
    "    hrules=True,\n",
    "    column_format=\"llccccc\"\n",
    ")\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Draw some ROC curves</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a ROC curve for the given method\n",
    "\n",
    "def compute_auc(target, prob):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, prob)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc, tpr, fpr\n",
    "\n",
    "def draw_roc_curve(data, grouping, model_name, colors, export_path='roc_plots', show_title=False, figsize=(4, 3.5)):\n",
    "    fig, axs = plt.subplots(1, figsize=figsize)\n",
    "    data = data.copy().reset_index()\n",
    "    data = data.replace({'frame-difference': 'FD', 'rgb': 'RGB'})\n",
    "    data = data[data['model'] == model_name]\n",
    "    grouped = data.groupby(grouping)\n",
    "    \n",
    "    for model_group, all_predictions in grouped:\n",
    "        dataset_name, mode = model_group[0], model_group[1]\n",
    "\n",
    "        # find the run with best auc\n",
    "        # aucs = all_predictions.groupby('split_seed').apply(lambda x: compute_auc(x['target_label'].values, x['pred_prob'].values)[0])\n",
    "        # aucs = aucs.reset_index()\n",
    "        # idxmax = aucs[0].idxmax()\n",
    "        # chosen_seed = aucs.at[idxmax, 'split_seed']\n",
    "        valid_preds = all_predictions #all_predictions[all_predictions['split_seed'] == chosen_seed]\n",
    "\n",
    "        targets = valid_preds['target_label'].values\n",
    "        probs = valid_preds['pred_prob'].values\n",
    "        roc_auc, tpr, fpr = compute_auc(targets, probs)\n",
    "\n",
    "        line_name = '{}-{}'.format(dataset_name, mode)\n",
    "        linestyle= 'dashed' if mode == 'FD' else 'solid'\n",
    "        display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=line_name)\n",
    "        display.plot(ax=axs, linestyle=linestyle, color=colors[dataset_name])\n",
    "        \n",
    "    handles, labels = axs.get_legend_handles_labels()\n",
    "    labels = [l[:-13] for l in labels]  # a bit hacky, remove auc from the legend\n",
    "    axs.legend(handles, labels)\n",
    "    axs.grid()\n",
    "    if show_title:\n",
    "        axs.set_title('ROC for {}'.format(model_name))\n",
    "    if export_path is not None:\n",
    "        export_path = Path(export_path)\n",
    "        export_path.mkdir(parents=True, exist_ok=True)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(export_path / '{}.pdf'.format(model_name))\n",
    "    \n",
    "    \n",
    "\n",
    "def collect_all_datasets(ROOT, model):\n",
    "    model_folders = {\n",
    "        'ResNet18-2+1D': 'resnet18-2plus1d',\n",
    "        'ResNet18-3D': 'resnet18-3d',\n",
    "        'ResNet18-MixedConvolution-3D': 'resnet18-mc-3d',\n",
    "        'BiConvLSTM-ECCV2018': 'biconvlstm',\n",
    "        'SlowFast': 'slowfast',\n",
    "        'Video-Swim-Transformer-k400': 'videoswintransformer-k400',\n",
    "        'ViViT-k400': 'vivit-k400',\n",
    "        'DeVTR': 'devtr',\n",
    "        'ConvLSTM-AVSS2017': 'convlstm',\n",
    "    }\n",
    "\n",
    "    model_folder = model_folders[model]\n",
    "    pattern = '{}*'.format(model_folder)\n",
    "    runs = {\n",
    "        'SCF': list(Path(ROOT + '/runs/experiment=surveillance-camera-fight/').glob(pattern)),\n",
    "        'RLV': list(Path(ROOT + '/runs/experiment=real-life-violence/').glob(pattern)),\n",
    "        'RWF-2000': list(Path(ROOT + '/runs/experiment=RWF-2000/').glob(pattern))\n",
    "    }\n",
    "\n",
    "    dfs = []\n",
    "    for k, v in runs.items():\n",
    "        for r in v:\n",
    "            df = collect_all(model, r, 'preds_bus-violence.csv')\n",
    "            df['dataset'] = k\n",
    "            dfs.append(df)\n",
    "\n",
    "    predictions = pd.concat(dfs, ignore_index=True)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/media/dlearning/shared/ciampi.messina/results/video-violence-detection/\"\n",
    "\n",
    "models = ['SlowFast', 'Video-Swim-Transformer-k400', 'ResNet18-3D', 'BiConvLSTM-ECCV2018']\n",
    "colors = {\"SCF\": \"gray\", \"RLV\": \"green\", \"RWF-2000\": \"blue\"}\n",
    "grouping = ['dataset', 'mode']\n",
    "\n",
    "for model in models:\n",
    "    predictions = collect_all_datasets(ROOT, model)\n",
    "    draw_roc_curve(predictions, grouping, model, colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d5db8f019622d615ca890809f18355d86bfc017d78ae2e84089baa8b3e79ed9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
